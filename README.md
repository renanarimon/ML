# ML
### data science & AI

* clean data
* vizualization
* Classification models<br>

### notbooks:
#### fashion Mnist
![image](https://user-images.githubusercontent.com/77155986/147161958-08175281-bcc5-4cb3-93f0-d66cfcf293cc.png)

#### cats vs dogs


In this project, the main methods I have used is:
1.	Scale: standardize the dataset by standard-scaler.
2.	PCA: dimensionality reduction.
my goal was to reach the best accuracy with lowest number of components, so I have tried to get the best balance between both.
3.	GridSearch: find best parameters in each model (using cross-validation).
4.	pipeline: scaling, pca, and fit model.
5.	Ensamble learning models: <br>
*	Logistic regression
*	KNN 
*	Random forest
*	XGBoost
*	Gradient Boost
*	Voting
*	Stacking<br>

Models I used but didn’t perform well, so isn’t in the notebooks:
*	Ada Boost
*	K-means

